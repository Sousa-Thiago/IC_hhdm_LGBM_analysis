{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f145990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 14:05:57.462371: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-14 14:05:57.522228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/eos/user/t/thenriqu/Dark_Matter/LGBM_hhdm_analysis/')\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import hepherolib.data as data\n",
    "import tensorflow as tf\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from lgbm.controllers_lgb_v2 import LGBLearner, LGBModel\n",
    "\n",
    "# Disable GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46faaf43",
   "metadata": {},
   "source": [
    "# Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c296567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = '18'\n",
    "year_style = 2018\n",
    "dataset_year = '2018'\n",
    "basedir = '/eos/user/t/thenriqu/Dark_Matter/Amostras/hhdmAnalysis_deepJet_Regions/datasets'\n",
    "\n",
    "# Data folder\n",
    "dataset_name = basedir.split('/')[-2]\n",
    "data_path = f\"./data/{dataset_name}/{dataset_year}\"\n",
    "Path(data_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Setup models folders\n",
    "models_path = f\"./models/{dataset_name}/{dataset_year}\"\n",
    "Path(models_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f2b55",
   "metadata": {},
   "source": [
    "# Lendo Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de031714",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/eos/user/t/thenriqu/Dark_Matter/metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "ST = metadata.get(\"datasets\").get(\"ST\")\n",
    "TT = metadata.get(\"datasets\").get(\"TT\")\n",
    "ZZ = metadata.get(\"datasets\").get(\"ZZ\")\n",
    "WZ = metadata.get(\"datasets\").get(\"WZ\")\n",
    "DY = metadata.get(\"datasets\").get(\"DY\")\n",
    "RESIDUAL = metadata.get(\"datasets\").get(\"RESIDUAL\")\n",
    "DATA = metadata.get(\"datasets\").get(\"DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87f783",
   "metadata": {},
   "source": [
    "# Carregando os Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008040a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:34<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal_1000_100 (184662, 13)\n",
      "Signal_1000_200 (155516, 13)\n",
      "Signal_1000_300 (163180, 13)\n",
      "Signal_1000_400 (174503, 13)\n",
      "Signal_1000_600 (47113, 13)\n",
      "Signal_1000_800 (148510, 13)\n",
      "Signal_400_100 (112655, 13)\n",
      "Signal_400_200 (35615, 13)\n",
      "Signal_500_100 (130495, 13)\n",
      "Signal_500_200 (140136, 13)\n",
      "Signal_500_300 (118287, 13)\n",
      "Signal_600_100 (134052, 13)\n",
      "Signal_600_200 (156038, 13)\n",
      "Signal_600_300 (145565, 13)\n",
      "Signal_600_400 (128733, 13)\n",
      "Signal_800_100 (156662, 13)\n",
      "Signal_800_200 (148385, 13)\n",
      "Signal_800_300 (160871, 13)\n",
      "Signal_800_400 (169710, 13)\n",
      "Signal_800_600 (138418, 13)\n",
      "ST (94330, 13)\n",
      "TT (2647163, 13)\n",
      "ZZ (1924672, 13)\n",
      "WZ (24816, 13)\n",
      "DYJetsToLL (5897214, 13)\n",
      "Residual (537577, 13)\n"
     ]
    }
   ],
   "source": [
    "variables = [\"RegionID\", \"evtWeight\", \"MLP_score_torch\", \"LeadingLep_pt\", \"LepLep_pt\", \"LepLep_deltaR\", \"LepLep_deltaM\", \"MET_pt\", \"MET_LepLep_Mt\", \"MET_LepLep_deltaPhi\", \"TrailingLep_pt\", \"MT2LL\", \"Nbjets\"]\n",
    "ds = data.read_files(basedir, period, mode=\"normal\", features=variables)\n",
    "\n",
    "data.join_datasets(ds, \"ST\", ST.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"TT\", TT.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"ZZ\", ZZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"WZ\", WZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"DYJetsToLL\", DY.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"Residual\", RESIDUAL.get(period), mode=\"normal\")\n",
    "\n",
    "# Datasets to be used\n",
    "used_datasets = [\n",
    "    *[dt for dt in ds.keys() if dt.startswith(\"Signal_\")],\n",
    "    \"ST\",\n",
    "    \"TT\",\n",
    "    \"ZZ\",\n",
    "    \"WZ\",\n",
    "    \"DYJetsToLL\",\n",
    "    \"Residual\"\n",
    "]\n",
    "\n",
    "for dt_name in used_datasets:\n",
    "    print(dt_name, ds[dt_name].shape)\n",
    "\n",
    "# Delete every other dataset\n",
    "datasets_to_delete = [dt_name for dt_name in ds.keys() if dt_name not in used_datasets]\n",
    "for dt_name in datasets_to_delete:\n",
    "    del ds[dt_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f79cb5",
   "metadata": {},
   "source": [
    "# Models Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cad14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"multi_signal\"\n",
    "features = [\n",
    "    \"LeadingLep_pt\",\n",
    "    \"LepLep_deltaM\",\n",
    "    \"LepLep_deltaR\",\n",
    "    \"LepLep_pt\",\n",
    "    \"MET_LepLep_Mt\",\n",
    "    \"MET_LepLep_deltaPhi\",\n",
    "    \"MET_pt\",\n",
    "    \"MT2LL\",\n",
    "    \"Nbjets\",\n",
    "    \"TrailingLep_pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72ed16",
   "metadata": {},
   "source": [
    "# Predict usando LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c419b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [1:22:27<00:00, 190.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "lgb_model = LGBModel(model_fpath=f\"{models_path}/LGB_{base_model_name}-clf.model\")\n",
    "\n",
    "# Predict each dataset\n",
    "for dataset_name, dataset in tqdm(ds.items()):\n",
    "    X_features = dataset[features]\n",
    "    Y_pred = lgb_model.predict(X_features, features)\n",
    "    dataset[\"LGB_score\"] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5b359",
   "metadata": {},
   "source": [
    "# Notificar quando terminar o predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6703752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "  var msg = new SpeechSynthesisUtterance();\n",
       "  msg.text = \"Process completed!\";\n",
       "  window.speechSynthesis.speak(msg);\n",
       "  alert(\"Process completed!\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, HTML, Javascript\n",
    "\n",
    "display(Javascript(\"\"\"\n",
    "  var msg = new SpeechSynthesisUtterance();\n",
    "  msg.text = \"Process completed!\";\n",
    "  window.speechSynthesis.speak(msg);\n",
    "  alert(\"Process completed!\")\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e76ba8",
   "metadata": {},
   "source": [
    "# Salvado o Predict do LGBMClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5648aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}/{base_model_name}-predicted--lgb-data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d6567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
