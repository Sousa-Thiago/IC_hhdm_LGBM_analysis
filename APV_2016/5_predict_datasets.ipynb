{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8bc64f",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a131de-cde0-4ebc-a503-97c76ce87521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 15:25:00.137918: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 15:25:00.188219: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/eos/user/t/thenriqu/Dark_Matter/LGBM_hhdm_analysis/')\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import hepherolib.data as data\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from lgbm.controllers_lgb_v2 import LGBLearner, LGBModel\n",
    "\n",
    "# Disable GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933516cd-e817-4980-bb32-c02c4960ce72",
   "metadata": {},
   "source": [
    "# Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad288b9-b7f7-4c4d-9468-e96796fdb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 'APV_16'\n",
    "year_style = 2016\n",
    "dataset_year = \"APV_2016\"\n",
    "basedir = '/eos/user/t/thenriqu/Dark_Matter/Amostras/hhdmAnalysis_deepJet_Regions/datasets'\n",
    "\n",
    "# Data folder\n",
    "dataset_name = basedir.split('/')[-2]\n",
    "data_path = f\"./data/{dataset_name}/{dataset_year}\"\n",
    "Path(data_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Setup models folders\n",
    "models_path = f\"./models/{dataset_name}/{dataset_year}\"\n",
    "Path(models_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fa024-1c8c-4459-ba59-fb214e27e04c",
   "metadata": {},
   "source": [
    "# Lendo metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cda459-65fe-4604-be8c-3e7b3daf7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/eos/user/t/thenriqu/Dark_Matter/metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "ST = metadata.get(\"datasets\").get(\"ST\")\n",
    "TT = metadata.get(\"datasets\").get(\"TT\")\n",
    "ZZ = metadata.get(\"datasets\").get(\"ZZ\")\n",
    "WZ = metadata.get(\"datasets\").get(\"WZ\")\n",
    "DY = metadata.get(\"datasets\").get(\"DY\")\n",
    "RESIDUAL = metadata.get(\"datasets\").get(\"RESIDUAL\")\n",
    "DATA = metadata.get(\"datasets\").get(\"DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8d603-8d39-4214-91d3-bdf1dbe58563",
   "metadata": {},
   "source": [
    "# Lendo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2607f4d-60f1-44d8-9775-bf17fb1f1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:13<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal_1000_100 (88335, 13)\n",
      "Signal_1000_200 (88586, 13)\n",
      "Signal_1000_300 (88409, 13)\n",
      "Signal_1000_400 (84874, 13)\n",
      "Signal_1000_600 (84624, 13)\n",
      "Signal_1000_800 (70928, 13)\n",
      "Signal_400_100 (59663, 13)\n",
      "Signal_400_200 (52864, 13)\n",
      "Signal_500_100 (68983, 13)\n",
      "Signal_500_200 (67010, 13)\n",
      "Signal_500_300 (57893, 13)\n",
      "Signal_600_100 (72558, 13)\n",
      "Signal_600_200 (73458, 13)\n",
      "Signal_600_300 (66828, 13)\n",
      "Signal_600_400 (59176, 13)\n",
      "Signal_800_100 (84368, 13)\n",
      "Signal_800_200 (83831, 13)\n",
      "Signal_800_300 (82955, 13)\n",
      "Signal_800_400 (80383, 13)\n",
      "Signal_800_600 (66585, 13)\n",
      "ST (25940, 13)\n",
      "TT (659085, 13)\n",
      "ZZ (475316, 13)\n",
      "WZ (12610, 13)\n",
      "DYJetsToLL (1941030, 13)\n",
      "Residual (251230, 13)\n"
     ]
    }
   ],
   "source": [
    "variables = [\"RegionID\", \"evtWeight\", \"MLP_score_torch\", \"LeadingLep_pt\", \"LepLep_pt\", \"LepLep_deltaR\", \"LepLep_deltaM\", \"MET_pt\", \"MET_LepLep_Mt\", \"MET_LepLep_deltaPhi\", \"TrailingLep_pt\", \"MT2LL\", \"Nbjets\"]\n",
    "ds = data.read_files(basedir, period, mode=\"normal\", features=variables)\n",
    "\n",
    "data.join_datasets(ds, \"ST\", ST.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"TT\", TT.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"ZZ\", ZZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"WZ\", WZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"DYJetsToLL\", DY.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"Residual\", RESIDUAL.get(period), mode=\"normal\")\n",
    "\n",
    "# Datasets to be used\n",
    "used_datasets = [\n",
    "    *[dt for dt in ds.keys() if dt.startswith(\"Signal_\")],\n",
    "    \"ST\",\n",
    "    \"TT\",\n",
    "    \"ZZ\",\n",
    "    \"WZ\",\n",
    "    \"DYJetsToLL\",\n",
    "    \"Residual\"\n",
    "]\n",
    "\n",
    "for dt_name in used_datasets:\n",
    "    print(dt_name, ds[dt_name].shape)\n",
    "\n",
    "# Delete every other dataset\n",
    "datasets_to_delete = [dt_name for dt_name in ds.keys() if dt_name not in used_datasets]\n",
    "for dt_name in datasets_to_delete:\n",
    "    del ds[dt_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed65a04-0204-480a-b8e7-a104e9976e97",
   "metadata": {},
   "source": [
    "# Modelo metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b475a9f8-f079-450b-90e3-cdc8247574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"multi_signal\"\n",
    "features = [\n",
    "    \"LeadingLep_pt\",\n",
    "    \"LepLep_deltaM\",\n",
    "    \"LepLep_deltaR\",\n",
    "    \"LepLep_pt\",\n",
    "    \"MET_LepLep_Mt\",\n",
    "    \"MET_LepLep_deltaPhi\",\n",
    "    \"MET_pt\",\n",
    "    \"MT2LL\",\n",
    "    \"Nbjets\",\n",
    "    \"TrailingLep_pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676f3e4-fb4c-43ce-af32-dbbedfbe4723",
   "metadata": {},
   "source": [
    "# Predict usando LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb55b752-3d9c-43d4-b78c-395b368af69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [30:01<00:00, 69.27s/it] \n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "lgb_model = LGBModel(model_fpath=f\"{models_path}/LGB_{base_model_name}-clf.model\")\n",
    "\n",
    "# Predict each dataset\n",
    "for dataset_name, dataset in tqdm(ds.items()):\n",
    "    X_features = dataset[features]\n",
    "    Y_pred = lgb_model.predict(X_features, features)\n",
    "    dataset[\"LGB_score\"] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5902e39-4d47-4277-a07e-5eb0aaffa952",
   "metadata": {},
   "source": [
    "# Pedrict usando MLP Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083a4736-ce08-4c35-8b2c-b3f611bea625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/26 [00:09<03:58,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/26 [00:20<04:09, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/26 [00:31<04:00, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 4/26 [00:41<03:53, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 5/26 [00:51<03:33, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 6/26 [00:59<03:09,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 7/26 [01:06<02:46,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 8/26 [01:12<02:20,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 9/26 [01:20<02:12,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 10/26 [01:27<02:02,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 11/26 [01:34<01:49,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 12/26 [01:42<01:45,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 13/26 [01:50<01:40,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 14/26 [01:58<01:33,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 15/26 [02:04<01:21,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 16/26 [02:14<01:20,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 17/26 [02:23<01:15,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325/325 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 18/26 [02:32<01:09,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 19/26 [02:41<01:00,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 20/26 [02:48<00:49,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 21/26 [02:51<00:32,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575/2575 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 22/26 [04:03<01:44, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 23/26 [05:00<01:46, 35.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 24/26 [05:01<00:50, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7583/7583 [==============================] - 10s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 25/26 [09:47<01:43, 103.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982/982 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [10:14<00:00, 23.64s/it] \n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "mlp_model = load_model(f\"{models_path}/MLP_{base_model_name}-checkpoint.h5\")\n",
    "\n",
    "# Load zscore stats\n",
    "zscore = json.load(open(f\"{data_path}/MLP_{base_model_name}-weighted_stats.json\", \"r\"))\n",
    "\n",
    "# Predict each dataset\n",
    "for dataset_name, dataset in tqdm(ds.items()):\n",
    "    X_features = dataset[features].copy()\n",
    "    \n",
    "    # Since the model was trained under processed data, we need to preprocess it to predict\n",
    "    for feature in features:\n",
    "        X_features.loc[:, feature] = (X_features[feature] - zscore[feature][\"mean\"]) / zscore[feature][\"std\"]\n",
    "\n",
    "    Y_pred = mlp_model.predict(X_features, batch_size=256)\n",
    "    dataset[\"MLP_score_keras\"] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d511b-3efa-4e88-bece-3594818a11cf",
   "metadata": {},
   "source": [
    "# Salvar predict datasets\n",
    "\n",
    "Os plots da previsão serão feitos em outro código, pois a previsão do Keras é lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd47d39-875d-4da4-b62b-88a7b3b29d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}/{base_model_name}-predicted-data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ds, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
